{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/terryhill89/deep-learning-challenge/blob/main/AlphabetSoupCharity_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "RwxtN4_xEjUg",
    "outputId": "c7756bd6-2bb0-482b-ba13-91bedeab1307"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hzfpOG8eFawr",
    "outputId": "76a225a6-1570-402c-dde5-0b752e0075ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns=['EIN', 'NAME'])\n",
    "application_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JO7nmKuBGBVy",
    "outputId": "c2b81c97-0216-482b-bbab-e2163c5242c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jodd1iBWGF-Z",
    "outputId": "8796ebc9-2d01-486f-aa16-9f97afc48a0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "app_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhOsjVFoQ4lX",
    "outputId": "cef4079f-f9a1-445c-9dfc-198652aa9483"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "\n",
    "# set cutoff to 200, create dictionary from value_counts result, and initialize list for app types to replace\n",
    "cutoff = 200\n",
    "app_count_dict = dict(app_counts)\n",
    "application_types_to_replace = []\n",
    "\n",
    "# iterate through items in dictionary, add app types with value < cutoff to list\n",
    "for key, value in app_count_dict.items():\n",
    "    if value < cutoff:\n",
    "        application_types_to_replace.append(key)\n",
    "\n",
    "# create copy of df for reduced app types\n",
    "reduce_app_type_df = application_df\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    reduce_app_type_df['APPLICATION_TYPE'] = reduce_app_type_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "reduce_app_type_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm9H05SXU54m",
    "outputId": "eee686e2-c931-4ba0-d8ba-561a87056a08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: count, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value for binning\n",
    "class_counts = reduce_app_type_df['CLASSIFICATION'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8c7cAQYU_M2",
    "outputId": "af96fc2b-5465-42b1-c5d9-e1d936b6aee0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "class_counts.loc[class_counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "u6cP5fkkt-hP",
    "outputId": "b1eaeebe-e492-475a-b758-5bac1d1ea144"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assessing outliers for ASK_AMT var \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# creating boxplot for the ask amount\n",
    "ask_amount = application_df['ASK_AMT'].tolist()\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Distribution of Funding Amount Requested')\n",
    "ax1.set_ylabel('$')\n",
    "ax1.boxplot(ask_amount)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qelvzXrDRJo-",
    "outputId": "a6e0b8db-5e71-4358-af2b-75ad6fe17496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8206 potential outliers out of 34299 records\n",
      "That is 23.924895769555967% of the records\n"
     ]
    }
   ],
   "source": [
    "# Determine which data points are outside of the 1.5*IQR range\n",
    "quartiles = np.quantile(ask_amount,[.25,.75])\n",
    "iqr = quartiles[1]-quartiles[0]\n",
    "lower_bound = quartiles[0]-(1.5*iqr)\n",
    "upper_bound = quartiles[1]+(1.5*iqr)\n",
    "potential_outliers = []\n",
    "# potential_outliers = [potential_outliers.append(amount) if amount < lower_bound or amount > upper_bound else next for amount in ask_amount]\n",
    "\n",
    "for amount in ask_amount:\n",
    "    if amount < lower_bound or amount > upper_bound:\n",
    "        potential_outliers.append(amount)\n",
    "\n",
    "print(f\"There are {len(potential_outliers)} potential outliers out of {application_df.shape[0]} records\")\n",
    "print(f\"That is {len(potential_outliers)/application_df.shape[0]*100}% of the records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TW7o5z6DVHPu",
    "outputId": "c74a9e77-3ef8-40de-e720-0c4c5ba4d82c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "\n",
    "# set cutoff to 1000, create dictionary from value_counts result, and initialize list for classifications to replace\n",
    "cutoff = 1000\n",
    "class_count_dict = dict(class_counts)\n",
    "classifications_to_replace = []\n",
    "\n",
    "# iterate through items in dictionary, add classifications with value < cutoff to list\n",
    "for key, value in class_count_dict.items():\n",
    "    if value < cutoff:\n",
    "        classifications_to_replace.append(key)\n",
    "\n",
    "# create copy of dataframe for reduced classifications\n",
    "reduce_class_df = reduce_app_type_df\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    reduce_class_df['CLASSIFICATION'] = reduce_class_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "reduce_class_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "P0RP5HKQVXuu",
    "outputId": "44c22905-5d55-41f1-bc27-4350a2727cc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                   False   \n",
       "1       1   108590              1                   False   \n",
       "2       1     5000              0                   False   \n",
       "3       1     6692              1                   False   \n",
       "4       1   142590              1                   False   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                  True                 False                False   \n",
       "1                 False                 False                 True   \n",
       "2                 False                 False                False   \n",
       "3                 False                 False                 True   \n",
       "4                 False                 False                 True   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                False                False                False  ...   \n",
       "1                False                False                False  ...   \n",
       "2                False                 True                False  ...   \n",
       "3                False                False                False  ...   \n",
       "4                False                False                False  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0              False                   False                     False   \n",
       "1               True                   False                     False   \n",
       "2              False                   False                     False   \n",
       "3              False                    True                     False   \n",
       "4              False                   False                      True   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0               False             False                   False   \n",
       "1               False             False                   False   \n",
       "2               False             False                   False   \n",
       "3               False             False                   False   \n",
       "4               False             False                   False   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0            False              False                      True   \n",
       "1            False              False                      True   \n",
       "2            False              False                      True   \n",
       "3            False              False                      True   \n",
       "4            False              False                      True   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                     False  \n",
       "1                     False  \n",
       "2                     False  \n",
       "3                     False  \n",
       "4                     False  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "dummies_df = pd.get_dummies(reduce_class_df)\n",
    "dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NUOGjD6DVgBG"
   },
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = dummies_df.drop('IS_SUCCESSFUL', axis=1)\n",
    "y = dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4hq7W6jCVg5O"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyiHkVUjVyDz"
   },
   "source": [
    "# **Optimization Attempt 1**\n",
    "\n",
    "#### 1st attempt at optimizing the model, add another hidden layer to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEyGact7WYUs"
   },
   "source": [
    "## **Compile, Train and Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUuKtev1WnSE",
    "outputId": "3d27d266-0061-409a-bddd-6e72c7222d87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,860</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,830</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             â”‚         \u001b[38;5;34m3,520\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m4,860\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             â”‚         \u001b[38;5;34m1,830\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m31\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,241</span> (40.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,241\u001b[0m (40.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,241</span> (40.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,241\u001b[0m (40.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "#  build the model\n",
    "nn_model_op1 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model_op1.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=43))\n",
    "\n",
    "# New hidden layer 2\n",
    "nn_model_op1.add(tf.keras.layers.Dense(units=60, activation=\"relu\"))\n",
    "\n",
    "# third hidden layer\n",
    "nn_model_op1.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model_op1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model_op1.summary()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2DISgfZKXCFm"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model_op1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3zjioh0XFGt",
    "outputId": "821ab2eb-bb7a-4ebb-8366-d49165add949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.6947 - loss: 0.5991\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7243 - loss: 0.5596\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7274 - loss: 0.5512\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7265 - loss: 0.5541\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7387 - loss: 0.5428\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7349 - loss: 0.5455\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7330 - loss: 0.5476\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7378 - loss: 0.5434\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7313 - loss: 0.5483\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7352 - loss: 0.5432\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7392 - loss: 0.5408\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7315 - loss: 0.5457\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7352 - loss: 0.5444\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7356 - loss: 0.5429\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7346 - loss: 0.5413\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7351 - loss: 0.5436\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7385 - loss: 0.5393\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7397 - loss: 0.5426\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7387 - loss: 0.5416\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7396 - loss: 0.5406\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7449 - loss: 0.5361\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.7403 - loss: 0.5388\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7382 - loss: 0.5373\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7365 - loss: 0.5439\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7354 - loss: 0.5384\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7456 - loss: 0.5314\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7383 - loss: 0.5395\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7374 - loss: 0.5402\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7426 - loss: 0.5331\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7449 - loss: 0.5328\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7390 - loss: 0.5391\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7397 - loss: 0.5385\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7401 - loss: 0.5347\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7349 - loss: 0.5401\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7412 - loss: 0.5333\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7392 - loss: 0.5349\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7388 - loss: 0.5349\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7387 - loss: 0.5390\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7431 - loss: 0.5296\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7389 - loss: 0.5386\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.7441 - loss: 0.5321\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7434 - loss: 0.5338\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7421 - loss: 0.5360\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7438 - loss: 0.5339\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7414 - loss: 0.5346\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7400 - loss: 0.5363\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7393 - loss: 0.5344\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7379 - loss: 0.5402\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7386 - loss: 0.5352\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7343 - loss: 0.5407\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7403 - loss: 0.5367\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7397 - loss: 0.5334\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7402 - loss: 0.5340\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7398 - loss: 0.5343\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7405 - loss: 0.5328\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7405 - loss: 0.5323\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7463 - loss: 0.5279\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7439 - loss: 0.5273\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7368 - loss: 0.5353\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7424 - loss: 0.5334\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7376 - loss: 0.5350\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7428 - loss: 0.5310\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7386 - loss: 0.5337\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.7406 - loss: 0.5330\n",
      "Epoch 65/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7432 - loss: 0.5336\n",
      "Epoch 66/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7408 - loss: 0.5357\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7419 - loss: 0.5316\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7450 - loss: 0.5314\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.7384 - loss: 0.5356\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7445 - loss: 0.5302\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7426 - loss: 0.5332\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7394 - loss: 0.5329\n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7369 - loss: 0.5375\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7408 - loss: 0.5339\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7441 - loss: 0.5308\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7410 - loss: 0.5332\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7411 - loss: 0.5324\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7399 - loss: 0.5339\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7459 - loss: 0.5299\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7465 - loss: 0.5323\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7362 - loss: 0.5371\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7371 - loss: 0.5346\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7420 - loss: 0.5331\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.7409 - loss: 0.5335\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7405 - loss: 0.5331\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7397 - loss: 0.5323\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7438 - loss: 0.5305\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7409 - loss: 0.5326\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7437 - loss: 0.5307\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7396 - loss: 0.5336\n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7423 - loss: 0.5286\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7425 - loss: 0.5316\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7387 - loss: 0.5343\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7398 - loss: 0.5351\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7423 - loss: 0.5316\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7412 - loss: 0.5311\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7422 - loss: 0.5301\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7431 - loss: 0.5263\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.7372 - loss: 0.5345\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7397 - loss: 0.5406\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_op1 = nn_model_op1.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JDUqG1yXdj1",
    "outputId": "daca91be-488d-446d-8242-c42f3f48690b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 520us/step - accuracy: 0.7301 - loss: 0.5707\n",
      "Loss: 0.5707262754440308, Accuracy: 0.7301457524299622\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss_op1, model_accuracy_op1 = nn_model_op1.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss_op1}, Accuracy: {model_accuracy_op1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "q5iE_eG2XfI2"
   },
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_model_op1.save('Results/AlphabetSoupCharity_Optimization1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gGC1nCsaWQL"
   },
   "source": [
    "**Results:**\n",
    "* *1st optimization attempt failed. Accuracy has decreased*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eJdpnsIa8no"
   },
   "source": [
    "# **Optimization Attempt 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhNcmdlbGvYt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28x0HXVXcJRH"
   },
   "source": [
    "Decrease the number of layers, then decrease neurons per layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVrDQ5uIfiD6"
   },
   "source": [
    "## **Compile, Train and Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrIfTD75cJ8l",
    "outputId": "ae6a70ce-ccec-4b09-a351-d0c3b12cdce4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,640</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m2,640\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m61\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,361</span> (24.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,361\u001b[0m (24.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,361</span> (24.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,361\u001b[0m (24.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "#  build the model\n",
    "nn_model_op2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model_op2.add(tf.keras.layers.Dense(units=60, activation=\"relu\", input_dim=43))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model_op2.add(tf.keras.layers.Dense(units=60, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model_op2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model_op2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_zbNL6U7cV4n"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model_op2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHb2baSycavO",
    "outputId": "5dd45566-07ce-40a7-8b1a-326529dff321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - accuracy: 0.7030 - loss: 0.5934\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.7349 - loss: 0.5489\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7336 - loss: 0.5498\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.7320 - loss: 0.5526\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7361 - loss: 0.5471\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7318 - loss: 0.5473\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7351 - loss: 0.5470\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7341 - loss: 0.5486\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7368 - loss: 0.5431\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7300 - loss: 0.5475\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7332 - loss: 0.5433\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7378 - loss: 0.5438\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7320 - loss: 0.5452\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7334 - loss: 0.5458\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7389 - loss: 0.5409\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7332 - loss: 0.5432\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.7352 - loss: 0.5425\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7386 - loss: 0.5411\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7394 - loss: 0.5372\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7391 - loss: 0.5382\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7337 - loss: 0.5436\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7328 - loss: 0.5467\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7357 - loss: 0.5424\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7410 - loss: 0.5404\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7359 - loss: 0.5427\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7366 - loss: 0.5448\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7398 - loss: 0.5368\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7344 - loss: 0.5425\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7353 - loss: 0.5409\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7381 - loss: 0.5391\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7408 - loss: 0.5363\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7391 - loss: 0.5406\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7402 - loss: 0.5397\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7379 - loss: 0.5402\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7406 - loss: 0.5377\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7362 - loss: 0.5407\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7368 - loss: 0.5394\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7391 - loss: 0.5387\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7422 - loss: 0.5346\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7427 - loss: 0.5317\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7392 - loss: 0.5385\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7400 - loss: 0.5372\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7399 - loss: 0.5330\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7367 - loss: 0.5423\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7385 - loss: 0.5375\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7393 - loss: 0.5394\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7424 - loss: 0.5376\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7403 - loss: 0.5361\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7386 - loss: 0.5369\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7392 - loss: 0.5361\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7397 - loss: 0.5307\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7353 - loss: 0.5380\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7373 - loss: 0.5394\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7400 - loss: 0.5338\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7458 - loss: 0.5303\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7387 - loss: 0.5343\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.7386 - loss: 0.5382\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7433 - loss: 0.5295\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.7396 - loss: 0.5373\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7410 - loss: 0.5325\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7354 - loss: 0.5371\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7446 - loss: 0.5301\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7412 - loss: 0.5357\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7443 - loss: 0.5333\n",
      "Epoch 65/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7451 - loss: 0.5307\n",
      "Epoch 66/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7391 - loss: 0.5377\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7419 - loss: 0.5331\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7375 - loss: 0.5401\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7406 - loss: 0.5331\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7383 - loss: 0.5341\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7420 - loss: 0.5329\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7443 - loss: 0.5316\n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7418 - loss: 0.5346\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7445 - loss: 0.5288\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7424 - loss: 0.5325\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7462 - loss: 0.5276\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7404 - loss: 0.5371\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7447 - loss: 0.5303\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7398 - loss: 0.5361\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7441 - loss: 0.5299\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7389 - loss: 0.5369\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7384 - loss: 0.5344\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7412 - loss: 0.5351\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7410 - loss: 0.5377\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7409 - loss: 0.5349\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7407 - loss: 0.5322\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7410 - loss: 0.5336\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7378 - loss: 0.5355\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7401 - loss: 0.5343\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7397 - loss: 0.5335\n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7431 - loss: 0.5330\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7468 - loss: 0.5294\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7417 - loss: 0.5318\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7412 - loss: 0.5331\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7365 - loss: 0.5371\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7377 - loss: 0.5371\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7387 - loss: 0.5369\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7394 - loss: 0.5407\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7462 - loss: 0.5280\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7425 - loss: 0.5318\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_op2 = nn_model_op2.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHIJfty5cy64",
    "outputId": "c801e67c-25c4-4116-eb8c-88ead4ea9217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 540us/step - accuracy: 0.7286 - loss: 0.5615\n",
      "Loss: 0.5615001320838928, Accuracy: 0.7286297082901001\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss_op2, model_accuracy_op2 = nn_model_op2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss_op2}, Accuracy: {model_accuracy_op2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RMaf2pEpgnIy"
   },
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_model_op2.save('Results/AlphabetSoupCharity_Optimization2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxLpjvAjgt_w"
   },
   "source": [
    "**Results:**\n",
    "* *2nd optimization attempt failed. Decrease in Layers/neurons led to a slight decrease in the models accuracy.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "090RX1Uxjjw1"
   },
   "source": [
    "# **Optimization Attempt 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hbn1g-Kpj6n8"
   },
   "source": [
    "Start with the original model setup but drop some potentially unnecessary columns.\n",
    "* Drop `STATUS` and `SPECIAL_CONSIDERATIONS` Columns because they are simple Booleans describing a single factor they don't contribute that much to the decisions of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sT-j_-dzoBK7"
   },
   "source": [
    "## **Reprocessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "OVwBxgemof7F",
    "outputId": "bceb6421-f6e3-4903-a29d-c4626d50f7cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0     5000              1                   False                  True   \n",
       "1   108590              1                   False                 False   \n",
       "2     5000              0                   False                 False   \n",
       "3     6692              1                   False                 False   \n",
       "4   142590              1                   False                 False   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                 False                False                False   \n",
       "1                 False                 True                False   \n",
       "2                 False                False                False   \n",
       "3                 False                 True                False   \n",
       "4                 False                 True                False   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                False                False                False  ...   \n",
       "1                False                False                False  ...   \n",
       "2                 True                False                False  ...   \n",
       "3                False                False                False  ...   \n",
       "4                False                False                False  ...   \n",
       "\n",
       "   ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0               False          True              False   \n",
       "1               False         False               True   \n",
       "2               False          True              False   \n",
       "3                True         False              False   \n",
       "4                True         False              False   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                   False                     False               False   \n",
       "1                   False                     False               False   \n",
       "2                   False                     False               False   \n",
       "3                    True                     False               False   \n",
       "4                   False                      True               False   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0             False                   False            False   \n",
       "1             False                   False            False   \n",
       "2             False                   False            False   \n",
       "3             False                   False            False   \n",
       "4             False                   False            False   \n",
       "\n",
       "   INCOME_AMT_5M-10M  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the processed data just prior to categorical conversion and drop selected columns\n",
    "op3_df = reduce_class_df.drop(['STATUS', 'SPECIAL_CONSIDERATIONS'], axis=1)\n",
    "\n",
    "# convert categorical data to numeric\n",
    "op3_dummies_df = pd.get_dummies(op3_df)\n",
    "op3_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oWJ16NrsosZA"
   },
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X_op3 = op3_dummies_df.drop('IS_SUCCESSFUL', axis=1)\n",
    "y_op3 = op3_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_op3_train, X_op3_test, y_op3_train, y_op3_test = train_test_split(X_op3, y_op3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_Qhq0YZ0owGX"
   },
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler_op3 = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler_op3 = scaler_op3.fit(X_op3_train)\n",
    "\n",
    "# Scale the data\n",
    "X_op3_train_scaled = X_scaler_op3.transform(X_op3_train)\n",
    "X_op3_test_scaled = X_scaler_op3.transform(X_op3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVb8RrCTo_N2"
   },
   "source": [
    "## **Compile, Train and Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_vJN0xWpBFM",
    "outputId": "2716fd4a-8118-43f1-b422-ccaaad930e35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,460</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,830</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m2,460\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             â”‚         \u001b[38;5;34m1,830\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m31\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,321</span> (16.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,321\u001b[0m (16.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,321</span> (16.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,321\u001b[0m (16.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "#  build the model\n",
    "nn_model_op3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model_op3.add(tf.keras.layers.Dense(units=60, activation=\"relu\", input_dim=40))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model_op3.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model_op3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model_op3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2MVsXQRrpLXt"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model_op3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKnL376r-vuK",
    "outputId": "7e6b1de1-ccf6-4209-d627-85d48d835d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - accuracy: 0.7056 - loss: 0.5858\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7304 - loss: 0.5516\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7300 - loss: 0.5521\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7299 - loss: 0.5536\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7367 - loss: 0.5457\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7362 - loss: 0.5474\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7343 - loss: 0.5472\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7357 - loss: 0.5456\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7383 - loss: 0.5409\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7341 - loss: 0.5456\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7374 - loss: 0.5426\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.7370 - loss: 0.5417\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7377 - loss: 0.5385\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7414 - loss: 0.5364\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7393 - loss: 0.5410\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7275 - loss: 0.5503\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.7390 - loss: 0.5389\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7372 - loss: 0.5446\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7353 - loss: 0.5433\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7364 - loss: 0.5442\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7381 - loss: 0.5426\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7314 - loss: 0.5443\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7372 - loss: 0.5402\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7323 - loss: 0.5456\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7408 - loss: 0.5380\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7340 - loss: 0.5431\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.7391 - loss: 0.5404\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.7388 - loss: 0.5405\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7351 - loss: 0.5423\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7372 - loss: 0.5390\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7374 - loss: 0.5403\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7306 - loss: 0.5422\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7453 - loss: 0.5329\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7435 - loss: 0.5362\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7374 - loss: 0.5398\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7384 - loss: 0.5416\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7386 - loss: 0.5383\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7405 - loss: 0.5372\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7372 - loss: 0.5398\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7394 - loss: 0.5382\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7417 - loss: 0.5371\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7351 - loss: 0.5446\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7340 - loss: 0.5428\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7412 - loss: 0.5371\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7397 - loss: 0.5385\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7377 - loss: 0.5387\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7407 - loss: 0.5367\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7409 - loss: 0.5378\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7387 - loss: 0.5399\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7398 - loss: 0.5355\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7361 - loss: 0.5412\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7414 - loss: 0.5370\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7413 - loss: 0.5385\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7389 - loss: 0.5372\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7441 - loss: 0.5330\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7400 - loss: 0.5343\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7378 - loss: 0.5381\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7411 - loss: 0.5354\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7404 - loss: 0.5343\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7422 - loss: 0.5348\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7413 - loss: 0.5347\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7377 - loss: 0.5407\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7369 - loss: 0.5391\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7368 - loss: 0.5405\n",
      "Epoch 65/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7407 - loss: 0.5353\n",
      "Epoch 66/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7404 - loss: 0.5377\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7416 - loss: 0.5366\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7401 - loss: 0.5344\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7410 - loss: 0.5356\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7397 - loss: 0.5363\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7449 - loss: 0.5347\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7441 - loss: 0.5340\n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7418 - loss: 0.5370\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7340 - loss: 0.5426\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.7436 - loss: 0.5342\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7398 - loss: 0.5368\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7434 - loss: 0.5339\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.7432 - loss: 0.5322\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7366 - loss: 0.5367\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7362 - loss: 0.5371\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7386 - loss: 0.5383\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7430 - loss: 0.5310\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7410 - loss: 0.5349\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7413 - loss: 0.5340\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7399 - loss: 0.5364\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7371 - loss: 0.5379\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7375 - loss: 0.5393\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7408 - loss: 0.5352\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7428 - loss: 0.5325\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7424 - loss: 0.5327\n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7447 - loss: 0.5313\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7387 - loss: 0.5385\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7364 - loss: 0.5375\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7375 - loss: 0.5394\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7374 - loss: 0.5360\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7368 - loss: 0.5387\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.7392 - loss: 0.5370\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7376 - loss: 0.5373\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7418 - loss: 0.5308\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7415 - loss: 0.5341\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_op3 = nn_model_op3.fit(X_op3_train_scaled, y_op3_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQ_-WFAyA6TZ",
    "outputId": "81b32396-7236-4ccd-e366-f8f9e034d40e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 595us/step - accuracy: 0.7279 - loss: 0.5592\n",
      "Loss: 0.5592214465141296, Accuracy: 0.7279300093650818\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss_op3, model_accuracy_op3 = nn_model_op3.evaluate(X_op3_test_scaled,y_op3_test,verbose=2)\n",
    "print(f\"Loss: {model_loss_op3}, Accuracy: {model_accuracy_op3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2BhGKmLQWLFg"
   },
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_model_op3.save('Results/AlphabetSoupCharity_Optimization2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QacqMx0A8XC"
   },
   "source": [
    "**Results:**\n",
    "\n",
    "3rd optimization attempt has failed. Removing the status and special considerations columns from the model had very little impact on the accuracy of the model only causing a bit of an increase in accuracy.\n",
    "\n",
    "The loss and accuracy were nearly the same as the first optimization model showing at **L:** 0.5712 and **A:** 0.7283 with a slight increase in accuracy showing at **L:** 0.5583 and **A:** 0.7296 for model 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6zhhRnewNSW"
   },
   "source": [
    "# **Final Optimization Attempt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qSZ6QjUxSNz"
   },
   "source": [
    "In the final attempt Compile, Train and Evaluate the model using Automated Tuning Approach to see if the accuracy will increase.\n",
    "\n",
    "**!pip install keras_tuner** \n",
    "and then\n",
    "\n",
    "**import the kerastuner library**\n",
    "\n",
    "**import keras_tuner as kt**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4Q9MQF3w1W-"
   },
   "source": [
    "## **Compile, Train and Evaluate the Model using Automated Tuning Approach**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "p9AzMZv-CgOy"
   },
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_model_op3.save('Results/AlphabetSoupCharity_Optimization3.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fkU6kropE-PQ"
   },
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('first_units',\n",
    "                     min_value=2,\n",
    "                     max_value=160,\n",
    "                     step=2),\n",
    "        activation=activation,\n",
    "        input_dim=43))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=2,\n",
    "            max_value=160,\n",
    "            step=43),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qe8mJe0FY4Z",
    "outputId": "add7dfb5-adbc-40c0-a909-1418085e1eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.12/site-packages (from keras_tuner) (3.8.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from keras_tuner) (23.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from keras_tuner) (2.32.2)\n",
      "Collecting kt-legacy (from keras_tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_tuner) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_tuner) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.12/site-packages (from keras->keras_tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->keras_tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->keras_tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->keras_tuner) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->keras_tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optree->keras->keras_tuner) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras->keras_tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras->keras_tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras->keras_tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner\n",
    "# Import the kerastuner library\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "4CuS2maQFeUw"
   },
   "outputs": [],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=100,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6giZh7l3_99",
    "outputId": "9fd4dd95-9e68-4e13-8690-db01ec91e5ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 207 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.7303789854049683\n",
      "\n",
      "Best val_accuracy So Far: 0.7330612540245056\n",
      "Total elapsed time: 00h 11m 28s\n",
      "\n",
      "Search: Running Trial #208\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "tanh              |relu              |activation\n",
      "38                |74                |first_units\n",
      "2                 |1                 |num_layers\n",
      "131               |88                |units_0\n",
      "88                |2                 |units_1\n",
      "2                 |2                 |units_2\n",
      "45                |45                |units_3\n",
      "45                |131               |units_4\n",
      "12                |12                |tuner/epochs\n",
      "0                 |4                 |tuner/initial_epoch\n",
      "2                 |4                 |tuner/bracket\n",
      "0                 |2                 |tuner/round\n",
      "\n",
      "Epoch 1/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.7020 - loss: 0.5897 - val_accuracy: 0.7278 - val_loss: 0.5629\n",
      "Epoch 2/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7253 - loss: 0.5659 - val_accuracy: 0.7289 - val_loss: 0.5589\n",
      "Epoch 3/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.7273 - loss: 0.5591 - val_accuracy: 0.7277 - val_loss: 0.5609\n",
      "Epoch 4/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7323 - loss: 0.5530 - val_accuracy: 0.7268 - val_loss: 0.5617\n",
      "Epoch 5/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.7290 - loss: 0.5533 - val_accuracy: 0.7262 - val_loss: 0.5550\n",
      "Epoch 6/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7290 - loss: 0.5523 - val_accuracy: 0.7310 - val_loss: 0.5547\n",
      "Epoch 7/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.7309 - loss: 0.5531 - val_accuracy: 0.7208 - val_loss: 0.5565\n",
      "Epoch 8/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7326 - loss: 0.5518 - val_accuracy: 0.7261 - val_loss: 0.5542\n",
      "Epoch 9/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7317 - loss: 0.5511 - val_accuracy: 0.7282 - val_loss: 0.5552\n",
      "Epoch 10/12\n",
      "\u001b[1m804/804\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7310 - loss: 0.5502 - val_accuracy: 0.7250 - val_loss: 0.5557\n",
      "Epoch 11/12\n",
      "\u001b[1m107/804\u001b[0m \u001b[32mâ”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7485 - loss: 0.5356"
     ]
    }
   ],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=200,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LuXNe8adPEgz",
    "outputId": "9fcb8865-a0f7-4953-c10e-1abcb9f4cfd4"
   },
   "outputs": [],
   "source": [
    "# Evaluate best model against full test data\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsAo6fGL9yCc"
   },
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "best_model.save('AlphabetSoupCharity_Optimization.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PV9zQgE7lU0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mxKIA_nC1r5"
   },
   "source": [
    "**Final Results:**\n",
    "\n",
    "Final optimization attempt was ***successful***. There was a sufficent increase using the Automated Tuning Approach. I ran the automization model several times with no improvement in performence. After adjusting the model a few times I seen high increase in accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyODos5cTPnNhvcFHxW6Hix3",
   "include_colab_link": true,
   "mount_file_id": "1Pjj29aqQuKAGPucl0bRgIpTVQVzj7btj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
